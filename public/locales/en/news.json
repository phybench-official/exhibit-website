{
  "news": "News",
  "post": {
    "alphaxiv1": "LLMs struggle with physical reasoning \n\n PHYBench is a new benchmark with 500 real-world physics problems. \n\n ğŸ“‰ Even top models fall short of human accuracy ğŸ“Š Highlights the challenge of true physical reasoning \n\n Trending #1 on alphaXiv ğŸ“ˆ",
    "alphaxiv2": "ğŸš¨Donâ€™t miss out on this high-impact week for AI and reinforcement learning, featuring greedy agents, test-time RL, and a powerful new benchmark for LLM physical reasoning ğŸš€ \n\n Check out the top 10 papers for the weekğŸ‘‡ \n\n - TTRL: Test-Time Reinforcement Learning\n - PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models\n - LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities\n - Describe Anything: Detailed Localized Image and Video Captioning\n - Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?\n - EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models\n - Planet as a Brain: Towards Internet of AgentSites based on AIOS Server\n - Tina: Tiny Reasoning Models via LoRA \n- Learning to Reason under Off-Policy Guidance\n - Boosting Generative Image Modeling via Joint Image-Feature Synthesis",
    "releasepaper": "ğŸ¤” Can Large Language Models truly grasp physics? \n ğŸŒ Introducing PHYBench! âœ¨ \n\n The PHYBench team is thrilled to announce our paper \"PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models\" went LIVE on arXiv on April 22, 2025! ğŸš€ \n\n  We've built a comprehensive benchmark to evaluate LLMs' physical perception and reasoning capabilities. \n ğŸ“Š Curious how current models fare in understanding the physical world? \n ğŸ‘‡ Read the full paper here:",
    "hfrank": "ğŸ¥³ HUGE NEWS! Absolutely THRILLED! ğŸ‰ \n\n Our dataset has successfully climbed to the #ï¸âƒ£ğŸ¥‰ spot (Third Place!) on the Hugging Face Datasets Trending list! âœ¨ Exactly on May 1, 2025! This is incredible! ğŸš€ \n\n A massive THANKS to the entire global community! ğŸ™ Your attention, stars, and usage have given our work such amazing recognition! ğŸ¤— \n\n  Haven't checked it out yet? ğŸ‘‡ Explore our dataset on Hugging Face now and let's accelerate AI research together!",
    "qwen3release": "ğŸš€ PHYBench Leaderboard Update | Qwen3 Joins the Race! \n Weâ€™ve just completed our latest evaluation of the Qwen3-235B-A22B model, with forced reasoning enabled via API to ensure full utilization of its inference capabilities.\n\n ğŸ“Š The results are in:\n EED Score: 40.76 \n Accuracy: 28.70% \n\n With these scores, Qwen3 ranks 4th on the PHYBench leaderboard â€” showcasing impressive progress in physical reasoning. \n ğŸ‰ Congratulations to the Ali Qwen team on this achievement!",
    "versionUpdate": "ğŸš€ Major update for AI physical reasoning! \n PHYBench project just released a significant upgrade: new interactive website with 20 mainstream model leaderboards, and deep insights into \"Superficial Reasoning\" when applying physical laws. \n Check out the insights & updated paper!",
    "grok4": "Grok4 Achieves New Physics Reasoning Record, Gap with Human Experts Remains\n\nPHYBench team releases Grok4's latest evaluation results: \n Grok 4 \t\t\t\t ACC: 42.33 \t EED: 53.03\n Gemini 2.5 Pro \t ACC: 36.87 \t EED: 49.46\n Human Expert \t ACC: 61.90 \t EED: 71.40\n\nGrok4 comprehensively surpasses previous SOTA Gemini 2.5 Pro, yet still significantly trails human expert baseline.\nNotably, while Grok4 demonstrates dominant performance on HLE, it only achieves marginal improvements on PHYBench, highlighting PHYBench's superior objectivity in measuring true model capabilities. Meanwhile, domestic Chinese models remain competitive and have not fallen behind. \nPeking University School of Physics will continuously update PHYBench, committed to providing the most objective evaluation for large language model physics reasoning assessment.",
    "wechatGroup": "ğŸ¤ Join PHYBench NIPS Discussion Group!\n\n To better communicate with the community, we've created a PHYBench NIPS discussion WeChat group.\n\n ğŸ¯ Discussion topics include:\n - Latest PHYBench developments\n - Physics AI research discussions\n - NIPS conference related exchanges\n - Technical Q&A\n\n ğŸ“± Scan the QR code below to join the group chat and connect directly with researchers!\n\n âš ï¸ Note: QR code expires in 7 days. If expired, please contact us for the latest QR code."
  },
  "hide": "Hide More",
  "show": "Show More"
}
